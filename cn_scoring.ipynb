{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b228366",
   "metadata": {},
   "source": [
    "# CN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883d2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3679df28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7337 entries, 0 to 7336\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    7337 non-null   object\n",
      " 1   score   7337 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 114.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                                                 text  score\n",
       " 0  苏州市物价局 您好您的来信收悉根据印发关于市区机动车停放服务收费改革意见的通知苏府号规定机动...      0\n",
       " 1  触目惊心东北名男子街头上演武林风倒地男子被车碾死 月日凌晨时分大连市的太原街和同泰街交会出一...     -1\n",
       " 2  以恋爱为名一女子诱骗网友到萍乡一传销窝点非法拘禁天 中国江西网讯徐政武见习记者薛柏武记者周再...     -1\n",
       " 3  杭州芊颜化妆品有限公司被爆涉传老板很嚣张-浦口人网 杭州芊颜化妆品有限公司被爆涉传老板很嚣张...     -1\n",
       " 4  蹊跷泰州一灵车停在屋里莫名起火把房子烧了麦泽利安的头颅-言 蹊跷泰州一灵车停在屋里莫名起火把...     -1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_score_source = pd.read_excel('sentiment_source/cn_train_data.xlsx')\n",
    "cn_score_source.info(), cn_score_source.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839e066",
   "metadata": {},
   "source": [
    "### TF-IDF, Ridge/XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c50fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183c6f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/t5/m480qyfn2vnbgmm98d9vyd2m0000gn/T/jieba.cache\n",
      "Loading model cost 0.335 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'RMSE': 0.5069569343992312,\n",
       "  'MAE': 0.3963599292140159,\n",
       "  'R2': 0.3948572548864834},\n",
       " {'RMSE': 0.5174405119816862,\n",
       "  'MAE': 0.42531049980135505,\n",
       "  'R2': 0.36957046523674986})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Chinese word segmentation\n",
    "def tokenize(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "cn_score_source['text_tokenized'] = cn_score_source['text'].apply(tokenize)\n",
    "\n",
    "# Step 2: TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(cn_score_source['text_tokenized'])\n",
    "y = cn_score_source['score']\n",
    "\n",
    "# Step 3: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train Ridge regression\n",
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "# Step 5: Train XGBoost regression\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate both models\n",
    "def evaluate(y_true, y_pred):\n",
    "    return {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"R2\": r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "ridge_metrics = evaluate(y_test, y_pred_ridge)\n",
    "xgb_metrics = evaluate(y_test, y_pred_xgb)\n",
    "\n",
    "ridge_metrics, xgb_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1485592",
   "metadata": {},
   "source": [
    "### Chinese FinBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49008606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7337/7337 [06:01<00:00, 20.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_path = \"FinBERT_L-12_H-768_A-12_pytorch\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertModel.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "cn_train_texts = cn_score_source[\"text\"].astype(str).tolist()\n",
    "\n",
    "# Extract [CLS] vectors as sentence vectors\n",
    "def get_cls_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # shape: (1, 768)\n",
    "    return cls_embedding.squeeze().numpy()\n",
    "\n",
    "# Apply to all news, track process with tqdm\n",
    "embeddings = [get_cls_embedding(text) for text in tqdm(cn_train_texts)]\n",
    "\n",
    "embed_df = pd.DataFrame(embeddings)\n",
    "embed_df[\"score\"] = cn_score_source[\"score\"].values\n",
    "embed_df.to_csv(\"sentiment_source/cn_train_bert.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d55aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3578/3578 [02:38<00:00, 22.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "model_path = \"FinBERT_L-12_H-768_A-12_pytorch\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertModel.from_pretrained(model_path)\n",
    "\n",
    "cn_news_path = \"data_final/cn_news.csv\"\n",
    "cn_news_df = pd.read_csv(cn_news_path)\n",
    "cn_texts = cn_news_df[\"Headlines\"].astype(str).tolist()\n",
    "\n",
    "# Extract [CLS] vectors as sentence vectors\n",
    "def get_cls_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # shape: (1, 768)\n",
    "    return cls_embedding.squeeze().numpy()\n",
    "\n",
    "# Apply to all news, track process with tqdm\n",
    "embeddings = [get_cls_embedding(text) for text in tqdm(cn_texts)]\n",
    "\n",
    "embed_df = pd.DataFrame(embeddings)\n",
    "embed_df.to_csv(\"data_final/cn_news_bert.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fdceb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ridge': {'RMSE': 0.4775876112290374,\n",
       "  'MAE': 0.37125230181712104,\n",
       "  'R2': 0.4629412456046471},\n",
       " 'MLP': {'RMSE': 0.49274726626273363,\n",
       "  'MAE': 0.364651839244405,\n",
       "  'R2': 0.4283053313501518},\n",
       " 'XGboost': {'RMSE': 0.4610354389982535,\n",
       "  'MAE': 0.3459513115125476,\n",
       "  'R2': 0.49952277909281206}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge, MLP, XGBoost for evaluation\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "df_train_bert = pd.read_csv(\"sentiment_source/cn_train_bert.csv\")\n",
    "X = df_train_bert.drop(columns=[\"score\"])\n",
    "y = df_train_bert[\"score\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"MLP\": MLPRegressor(hidden_layer_sizes=(512, 128), max_iter=300, random_state=42),\n",
    "    \"XGboost\": xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "}\n",
    "\n",
    "# Train, predict and evaluate\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, preds)),\n",
    "        \"MAE\": mean_absolute_error(y_test, preds),\n",
    "        \"R2\": r2_score(y_test, preds)\n",
    "    }\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1e0c7",
   "metadata": {},
   "source": [
    "### choose XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f04268d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>time</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>【2018年基金展望：公募弱冠重构江湖 私募借势探路国际】2018年是贯彻党的十九大精神的开...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.336547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>【2017年基金排名新鲜出炉 价值投资者尽享“王者盛宴”】随着2017年最后一个交易日结束，...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.363028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>【全年PMI增长平稳 中国经济换挡进入新阶段】近日，国家统计局服务业调查中心和中国物流与采购...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.356259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>【四部委：新能源车免征购置税延至2020年】12月27日，财政部等四部委发布公告称，财政部、...</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.002112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>【新华社：2018年A股“高歌”开门红 资本市场发展新年将“更上层楼”】2018年第一个交易...</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>0.468627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>3573</td>\n",
       "      <td>【中国人民银行行长易纲新年致辞】  原图</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.091625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>3574</td>\n",
       "      <td>【人民银行行长易纲看望慰问外汇储备经营管理人员】网页链接</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>-0.092145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>3575</td>\n",
       "      <td>【北向资金连续30日净流入 科技和医药股是今年两条增持主线】2019年是外资快速涌入A股市场...</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.283359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>3576</td>\n",
       "      <td>【隔夜外盘】欧美股市普跌，道指跌超180点，纳指跌0.67%，失守9000点整数关口；蔚来收...</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>-0.249491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>3577</td>\n",
       "      <td>【统计局：12月制造业PMI为50.2% 非制造业PMI为53.5%】统计局最新披露的数据显...</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.088412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3578 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                          Headlines  \\\n",
       "0              0  【2018年基金展望：公募弱冠重构江湖 私募借势探路国际】2018年是贯彻党的十九大精神的开...   \n",
       "1              1  【2017年基金排名新鲜出炉 价值投资者尽享“王者盛宴”】随着2017年最后一个交易日结束，...   \n",
       "2              2  【全年PMI增长平稳 中国经济换挡进入新阶段】近日，国家统计局服务业调查中心和中国物流与采购...   \n",
       "3              3  【四部委：新能源车免征购置税延至2020年】12月27日，财政部等四部委发布公告称，财政部、...   \n",
       "4              4  【新华社：2018年A股“高歌”开门红 资本市场发展新年将“更上层楼”】2018年第一个交易...   \n",
       "...          ...                                                ...   \n",
       "3573        3573                              【中国人民银行行长易纲新年致辞】  原图    \n",
       "3574        3574                     【人民银行行长易纲看望慰问外汇储备经营管理人员】网页链接     \n",
       "3575        3575  【北向资金连续30日净流入 科技和医药股是今年两条增持主线】2019年是外资快速涌入A股市场...   \n",
       "3576        3576  【隔夜外盘】欧美股市普跌，道指跌超180点，纳指跌0.67%，失守9000点整数关口；蔚来收...   \n",
       "3577        3577  【统计局：12月制造业PMI为50.2% 非制造业PMI为53.5%】统计局最新披露的数据显...   \n",
       "\n",
       "            time     score  \n",
       "0     2018-01-01  0.336547  \n",
       "1     2018-01-01  0.363028  \n",
       "2     2018-01-01  0.356259  \n",
       "3     2018-01-01  0.002112  \n",
       "4     2018-01-02  0.468627  \n",
       "...          ...       ...  \n",
       "3573  2019-12-31  0.091625  \n",
       "3574  2019-12-31 -0.092145  \n",
       "3575  2019-12-31  0.283359  \n",
       "3576  2019-12-31 -0.249491  \n",
       "3577  2019-12-31  0.088412  \n",
       "\n",
       "[3578 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_news_bert = pd.read_csv(\"data_final/cn_news_bert.csv\")\n",
    "cn_news = pd.read_csv(\"data_final/cn_news.csv\")\n",
    "\n",
    "X_train = df_train_bert.drop(columns=[\"score\"])\n",
    "y_train = df_train_bert[\"score\"]\n",
    "\n",
    "# Fit XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict sentiment scores on financial news\n",
    "xgb_scores = xgb_model.predict(cn_news_bert)\n",
    "\n",
    "# Normalize the scores to [-1, 1]\n",
    "min_score, max_score = xgb_scores.min(), xgb_scores.max()\n",
    "xgb_scores_norm = 2 * (xgb_scores - min_score) / (max_score - min_score) - 1 if max_score != min_score else np.zeros_like(xgb_scores)\n",
    "\n",
    "# Combine with date and headlines\n",
    "cn_news[\"score\"] = xgb_scores_norm\n",
    "cn_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_news = cn_news.drop(column = ['Unnamed: 0'])\n",
    "cn_news.to_csv(\"data_final/cn_news_scored.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876496ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance-nlp)",
   "language": "python",
   "name": "finance-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
